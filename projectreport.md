# spotifydatamining
Problem setting:

The global record music industry is worth $17.13 billion in 2018 and the greatest share of the revenue is generated by the streaming services. There are number of streaming services which are currently in the market looking to capture the most customer base and Spotify is currently the market leader in high content music streaming. The content on Spotify of course doesn’t come for free but there are many in app purchases which brings in the revenue for the app. On an average a customer shells out $10 for monthly subscription of the app. For this amount the customer’s expectation with the app is also high. Spotify invest chunk of its I revenue in R&D to bring the best service to the table for customer. Customer also expects better service in term of the content. This is where the recommendations are important, it gives the customers a better collection of content which is similar to their taste without them actually, physically giving feedback to the app. Data analytics is used for this purpose, finding historical data of the customer, analyzing the music the customer likes and presenting them with best options.


#Problem Definition :
How does Spotify do such an amazing job of choosing 30 songs for each person each week? Spotify takes into account each listener’s individual music taste. It uses algorithms to analyze the audio and textual content of music, allowing it to perform music identification, personalized recommendation, playlist creation, and analysis.
Here we will be learning how Spotify uses it’s algorithms to predict a song’s popularity . Song popularity is a ,etric based on the reach the song has to audience and with this model if we have the parameters beforehand we can predict its popularity.
We also added one more column for like/dislike and recorded the likes of a single user . We used this data to to build a model to predict if a given song will be loved by the user


#Data Description:
There are 16 columns in this dataset which specify the characteristic of each song and over 100 records (songs). The columns include features like song  name and artist and other attributes which are more specific to the song type like dance ability, beats per min and energy etc. The number of records will be around 19000. The data will have to scaled and the divided into training and validation dataset.
Data Exploration: 


 



 





 
The correlation plot was also plotted to see correlation of all the variables in the same plot.
 
From these plots we decided to remove some of the predictors in the dataset.


 
From the above summary of the linear regression model we ran on the training data we see that dance ability, instumentalness, liveness , audio valence and tempo were significant variables which has to be used.
We used the summary function abvailable in R to check for duplicates

 

From the above summary we see that songs like FEFE,MIA etc were repeated several times and to rectify this we used unique function . After unique function we got around 14,000 songs .

#Data Mining Tasks: 
Linear regression, random forest were used to predict the songpolularity while knn was used for the classification of liked songs.
LINEAR REGRESSION:
Linear regression is used to predict the value of an outcome variable Y based on one or more input predictor variables X. The aim is to establish a linear relationship (a mathematical formula) between the predictor variable(s) and the response variable, so that, we can use this formula to estimate the value of the response Y, when only the predictors (Xs) values are known.
The predictors were scaled to bring it in between -1 and 1. This was done because of different predictor ranges in the data.
Once they were scaled, model was built using training data.

 
After the model was built it was used on the validation dataset to evaluate its performance the validation dataset was made up of 30% of total data.
The different performance metrics were used on the results to find its goodness.
 
 
 
With 94.3% accuracy this model performs well for the data.
#RANDOM FORREST:
The random forest model is a type of additive model that makes predictions by combining decisions from a sequence of base models. More formally we can write this class of models as:
g(x)=f0(x)+f1(x)+f2(x)+...
where the final model g is the sum of simple base models fi. Here, each base classifier is a 
simple decision tree. This broad technique of using multiple models to obtain better 
predictive performance is called model ensemble. In random forests, all the base models are constructed independently using a different subsample of the data.


 


#user like prediction SYSTEM:
To recommend a user any songs based on his/her likes and dislikes, we added another column to the dataset called ’liking’ where the user inputs the values of 1 for like and 0 for dislike. 
We filled the values for 150 observations from which 100 were used as training data and 50 were used as validation data. Normalization and dimension reduction were also performed to get accurate results.
We decided to run the training data through logistic regression and KNN models to get a comparision.
#LOGISTIC REGRESSION:
  
As we can see from the ROC curve below:
•	Logistic regression is not an efficient model as the ROC curve almost follows a linear path.
•	Almost all the parameters were not significant as their p-value was more than 5%.
 

 
K-NEAREST NEIGHBOURS:
After logistic regression we used the knn method to calculate the predicted results and recommendation.
 
 
#Conclusion:
•	KNN gives the best results in comparison with logistic regression model.
•	K=1 is giving accurate results as compared with other values.
•	The values for true positive class and false negative classes are higher and significant for k=1.
•	Accuracy for KNN is 83%. Hence, this is a better model for prediction compared to Logistic regression.
•	Based on the user likings, the user would not like a particular with given parameter ratings.

